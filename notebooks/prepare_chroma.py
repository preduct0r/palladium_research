#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è ChromaDB –∏–∑ —Ñ–∞–π–ª–∞ ice_creame_data.txt
"""

import os
from langchain_community.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema import Document

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
CHROMA_DB_PATH = "chroma_db_ice_creame"
COLLECTION_NAME = "ice_creame"
DATA_FILE = "notebooks/ice_creame_data.txt"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–µ—Ä–∞ (—Ç–æ—Ç –∂–µ —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ open_chroma.py)
embedder = OpenAIEmbeddings(
    model="Qwen/Qwen3-Embedding-8B", 
    base_url="http://localhost:8100/v1",
    api_key="EMPTY"
)

def load_data_from_file(file_path: str):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑: {file_path}")
    
    documents = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if line:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
                doc = Document(
                    page_content=line,
                    metadata={
                        "source": file_path,
                        "line_number": line_num,
                        "doc_id": f"line_{line_num}"
                    }
                )
                documents.append(doc)
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(documents)}")
    return documents

def create_chroma_db(documents):
    """–°–æ–∑–¥–∞–µ—Ç ChromaDB –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    print(f"üîß –°–æ–∑–¥–∞–µ–º ChromaDB –≤: {CHROMA_DB_PATH}")
    print(f"üìÅ –ö–æ–ª–ª–µ–∫—Ü–∏—è: {COLLECTION_NAME}")
    
    # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
    if os.path.exists(CHROMA_DB_PATH):
        print(f"‚ö†Ô∏è  –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É: {CHROMA_DB_PATH}")
        import shutil
        shutil.rmtree(CHROMA_DB_PATH)
    
    # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embedder,
        collection_name=COLLECTION_NAME,
        persist_directory=CHROMA_DB_PATH
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑—É
    vectorstore.persist()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    count = vectorstore._collection.count()
    print(f"‚úÖ –ë–∞–∑–∞ —Å–æ–∑–¥–∞–Ω–∞! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ: {count}")
    
    return vectorstore

def test_search(vectorstore):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–∏—Å–∫ –≤ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –±–∞–∑–µ"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫...")
    
    test_queries = [
        "–¥–∂–µ–ª–∞—Ç–æ",
        "–º–æ—Ä–æ–∂–µ–Ω–æ–µ –∏—Ç–∞–ª—å—è–Ω—Å–∫–æ–µ",
        "–ø–∞–ª–ª–∞–¥–∏–π –∞—Ñ—Ñ–∏–Ω–∞–∂"
    ]
    
    for query in test_queries:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}'")
        results = vectorstore.similarity_search(query, k=3)
        print(f"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
        
        for i, doc in enumerate(results, 1):
            print(f"  {i}. {doc.page_content[:100]}...")

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–æ–∑–¥–∞–Ω–∏—è ChromaDB –¥–ª—è ice_creame –¥–∞–Ω–Ω—ã—Ö")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        documents = load_data_from_file(DATA_FILE)
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–∑—É
        vectorstore = create_chroma_db(documents)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º
        test_search(vectorstore)
        
        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! ChromaDB —Å–æ–∑–¥–∞–Ω–∞ –≤ –ø–∞–ø–∫–µ: {CHROMA_DB_PATH}")
        print(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è: {COLLECTION_NAME}")
        print(f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise
